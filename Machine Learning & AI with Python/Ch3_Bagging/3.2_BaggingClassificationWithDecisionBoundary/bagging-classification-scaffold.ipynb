{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "%matplotlib inline\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn import metrics\n",
                "import scipy.optimize as opt\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.metrics import accuracy_score\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Used for plotting later\n",
                "from matplotlib.colors import ListedColormap\n",
                "cmap_bold = ListedColormap(['#F7345E','#80C3BD'])\n",
                "cmap_light = ListedColormap(['#FFF4E5','#D2E3EF'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read the file 'agriland.csv' as a Pandas dataframe\n",
                "df = pd.read_csv('agriland.csv')\n",
                "\n",
                "# Take a quick look at the data\n",
                "# Note that the latitude & longitude values are normalized\n",
                "df.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set the values of latitude & longitude predictor variables\n",
                "X = df[['latitude', 'longitude']].values\n",
                "\n",
                "# Use the column \"land_type\" as the response variable\n",
                "y = df['land_type'].values\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data in train and test, with test size = 0.2 \n",
                "# and set random state as 44\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the max_depth of the decision tree\n",
                "max_depth = 5\n",
                "\n",
                "# Define a decision tree classifier with a max depth as defined above\n",
                "# and set the random_state as 44\n",
                "clf = DecisionTreeClassifier(max_depth=max_depth, random_state=44)\n",
                "\n",
                "# Fit the model on the training data\n",
                "clf.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the trained model to predict on the test set\n",
                "prediction = clf.predict(X_test)\n",
                "\n",
                "# Calculate the accuracy of the test predictions of a single tree\n",
                "single_acc = accuracy_score(y_test, prediction)\n",
                "\n",
                "# Print the accuracy of the tree\n",
                "print(f'Single tree Accuracy is {single_acc*100}%')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Complete the function below to get the prediction by bagging\n",
                "\n",
                "# Inputs: X_train, y_train to train your data\n",
                "# X_to_evaluate: Samples that you are goin to predict (evaluate)\n",
                "# num_bootstraps: how many trees you want to train\n",
                "# Output: An array of predicted classes for X_to_evaluate\n",
                "# Modify the return statement in the prediction_by_bagging function\n",
                "def prediction_by_bagging(X_train, y_train, X_to_evaluate, num_bootstraps):\n",
                "    predictions = []\n",
                "    for i in range(num_bootstraps):\n",
                "        resample_indexes = np.random.choice(np.arange(y_train.shape[0]), size=y_train.shape[0])\n",
                "        X_boot = X_train[resample_indexes]\n",
                "        y_boot = y_train[resample_indexes]\n",
                "        clf = DecisionTreeClassifier(max_depth=max_depth, random_state=44)\n",
                "        clf.fit(X_boot, y_boot)\n",
                "        pred = clf.predict(X_to_evaluate)\n",
                "        predictions.append(pred)\n",
                "    \n",
                "    # Convert average predictions to binary (or categorical) values\n",
                "    average_prediction = (np.mean(predictions, axis=0) > 0.5).astype(int)\n",
                "    return average_prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_bag_acc) ###         \n",
                "\n",
                "\n",
                "# Define the number of bootstraps\n",
                "num_bootstraps = 200\n",
                "\n",
                "# Calling the prediction_by_bagging function with appropriate parameters\n",
                "y_pred = prediction_by_bagging(X_train,y_train,X_test,num_bootstraps=num_bootstraps)\n",
                "\n",
                "# Compare the average predictions to the true test set values \n",
                "# and compute the accuracy \n",
                "bagging_accuracy = accuracy_score(y_test, y_pred)\n",
                "\n",
                "# Print the bagging accuracy\n",
                "print(f'Accuracy with Bootstrapped Aggregation is  {bagging_accuracy*100}%')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper code to plot accuracy vs number of bagged trees\n",
                "\n",
                "n = np.linspace(1,250,250).astype(int)\n",
                "acc = []\n",
                "for n_i in n:\n",
                "    acc.append(np.mean(prediction_by_bagging(X_train, y_train, X_test, n_i)==y_test))\n",
                "plt.figure(figsize=(10,8))\n",
                "plt.plot(n,acc,alpha=0.7,linewidth=3,color='#50AEA4', label='Model Prediction')\n",
                "plt.title('Accuracy vs. Number of trees in Bagging ',fontsize=24)\n",
                "plt.xlabel('Number of trees',fontsize=16)\n",
                "plt.ylabel('Accuracy',fontsize=16)\n",
                "plt.xticks(fontsize=12)\n",
                "plt.yticks(fontsize=12)\n",
                "plt.legend(loc='best',fontsize=12)\n",
                "plt.show();\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bagging Visualization\n",
                "\n",
                "Bagging does well to reduce overfitting, but only upto a certain extent.\n",
                "\n",
                "Vary the `max_depth` and `numboot` variables to see how Bagging helps reduce overfitting with the help of the visualization below"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Making plots for three different values of `max_depth`\n",
                "fig,axes = plt.subplots(1,3,figsize=(16,4))\n",
                "\n",
                "# Make a list of three max_depths to investigate\n",
                "max_depth = [2,5,100]\n",
                "\n",
                "# Fix the number of bootstraps\n",
                "numboot = 100\n",
                "\n",
                "for index,ax in enumerate(axes):\n",
                "\n",
                "    for i in range(numboot):\n",
                "        df_new = df.sample(frac=1,replace=True)\n",
                "        y = df_new.land_type.values\n",
                "        X = df_new[['latitude', 'longitude']].values\n",
                "        dtree = DecisionTreeClassifier(max_depth=max_depth[index])\n",
                "        dtree.fit(X, y)\n",
                "        ax.scatter(X[:, 0], X[:, 1], c=y-1, s=50,alpha=0.5,edgecolor=\"k\",cmap=cmap_bold) \n",
                "        plot_step_x1= 0.1\n",
                "        plot_step_x2= 0.1\n",
                "        x1min, x1max= X[:,0].min(), X[:,0].max()\n",
                "        x2min, x2max= X[:,1].min(), X[:,1].max()\n",
                "        x1, x2 = np.meshgrid(np.arange(x1min, x1max, plot_step_x1), np.arange(x2min, x2max, plot_step_x2) )\n",
                "        # Re-cast every coordinate in the meshgrid as a 2D point\n",
                "        Xplot= np.c_[x1.ravel(), x2.ravel()]\n",
                "\n",
                "        # Predict the class\n",
                "        y = dtree.predict( Xplot )\n",
                "        y= y.reshape( x1.shape )\n",
                "        cs = ax.contourf(x1, x2, y, alpha=0.02)\n",
                "        \n",
                "    ax.set_xlabel('Latitude',fontsize=14)\n",
                "    ax.set_ylabel('Longitude',fontsize=14)\n",
                "    ax.set_title(f'Max depth = {max_depth[index]}',fontsize=20)\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
