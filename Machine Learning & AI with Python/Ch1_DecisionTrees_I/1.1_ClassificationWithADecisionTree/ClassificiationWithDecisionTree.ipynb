{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from helper import plot_boundary\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Read the data file \"election_train.csv\" as a Pandas dataframe\n",
    "elect_train = pd.read_csv(\"election_train.csv\")\n",
    "\n",
    "# Read the data file \"election_test.csv\" as a Pandas dataframe\n",
    "elect_test = pd.read_csv(\"election_test.csv\")\n",
    "\n",
    "# Take a quick look at the train data\n",
    "elect_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tstate\tfipscode\tcounty\tpopulation\thispanic\tminority\tfemale\tunemployed\tincome\tnodegree\tbachelor\tinactivity\tobesity\tdensity\tcancer\ttrump\tclinton\tvotergap\twon\n",
    "0\tAlabama\t1001\tAutauga County\t50756\t2.842\t22.733\t51.475\t5.2\t54366\t13.8\t21.9\t28.6\t34.1\t91.8\t186.5\t73.436\t23.957\t49.479\t1\n",
    "1\tAlabama\t1003\tBaldwin County\t179878\t4.550\t12.934\t51.261\t5.5\t49626\t11.0\t28.6\t22.3\t27.4\t114.6\t229.4\t77.351\t19.565\t57.786\t1\n",
    "2\tAlabama\t1007\tBibb County\t21587\t2.409\t23.930\t46.110\t6.6\t39546\t22.1\t10.2\t33.9\t40.3\t36.8\t230.3\t76.966\t21.422\t55.544\t1\n",
    "3\tAlabama\t1009\tBlount County\t58345\t8.954\t4.229\t50.592\t5.4\t45567\t21.9\t12.3\t28.0\t34.6\t88.9\t205.3\t89.852\t8.470\t81.382\t1\n",
    "4\tAlabama\t1011\tBullock County\t10985\t7.526\t72.831\t45.241\t7.8\t26580\t34.5\t14.1\t31.7\t43.0\t17.5\t211.2\t24.229\t75.090\t-50.862\t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### edTest(test_data) ###\n",
    "# Set the columns minority and bachelor as train data predictors\n",
    "X_train = elect_train[['minority', 'bachelor']]\n",
    "\n",
    "# Set the columns minority and bachelor as test data predictors\n",
    "X_test = elect_test[['minority', 'bachelor']]\n",
    "\n",
    "# Set the column \"won\" as the train response variable\n",
    "y_train = elect_train['won']\n",
    "\n",
    "# Set the column \"won\" as the test response variable\n",
    "y_test = elect_test['won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### edTest(test_models) ###\n",
    "\n",
    "# Initialize a Decision Tree classifier with a depth of 2\n",
    "dt1 = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# Fit the classifier on the train data\n",
    "dt1.fit(X_train, y_train)\n",
    "\n",
    "# Initialize a Decision Tree classifier with a depth of 10\n",
    "dt2 = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "# Fit the classifier on the train data\n",
    "dt2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Call the function plot_boundary from the helper file to get \n",
    "# the decision boundaries of both the classifiers\n",
    "plot_boundary(elect_train, dt1, dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set of predictor columns\n",
    "pred_cols = ['minority', 'density','hispanic','obesity','female','income','bachelor','inactivity']\n",
    "\n",
    "# Use the columns above as the features to \n",
    "# get the predictor set from the train data\n",
    "X_train = elect_train[pred_cols]\n",
    "\n",
    "# Use the columns above as the features to \n",
    "# get the predictor set from the test data\n",
    "X_test = elect_test[pred_cols]\n",
    "\n",
    "# Initialize a Decision Tree classifier with a depth of 2\n",
    "dt1 = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "# Initialize a Decision Tree classifier with a depth of 10\n",
    "dt2 = DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "# Initialize a Decision Tree classifier with a depth of 15\n",
    "dt3 = DecisionTreeClassifier(max_depth=15)\n",
    "\n",
    "# Fit all the classifier on the train data\n",
    "dt1.fit(X_train, y_train)\n",
    "dt2.fit(X_train, y_train)\n",
    "dt3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "### edTest(test_accuracy) ###\n",
    "\n",
    "# Compute the train and test accuracy for the first decision tree classifier of depth 2\n",
    "dt1_train_acc = dt1.score(X_train, y_train)\n",
    "dt1_test_acc = dt1.score(X_test, y_test)\n",
    "\n",
    "# Compute the train and test accuracy for the second decision tree classifier of depth 10\n",
    "dt2_train_acc = dt2.score(X_train, y_train)\n",
    "dt2_test_acc = dt2.score(X_test, y_test)\n",
    "\n",
    "# Compute the train and test accuracy for the third decision tree classifier of depth 15\n",
    "dt3_train_acc = dt3.score(X_train, y_train)\n",
    "dt3_test_acc = dt3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Helper code to plot the scores of each classifier as a table\n",
    "pt = PrettyTable()\n",
    "pt.field_names = ['Max Depth', 'Number of Features', 'Train Accuracy', 'Test Accuracy']\n",
    "pt.add_row([2, len(pred_cols), round(dt1_train_acc, 4), round(dt1_test_acc,4)])\n",
    "pt.add_row([10, len(pred_cols), round(dt2_train_acc,4), round(dt2_test_acc,4)])\n",
    "pt.add_row([15, len(pred_cols), round(dt3_train_acc,4), round(dt3_test_acc,4)])\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+-----------+--------------------+----------------+---------------+\n",
    "| Max Depth | Number of Features | Train Accuracy | Test Accuracy |\n",
    "+-----------+--------------------+----------------+---------------+\n",
    "|     2     |         8          |     0.8924     |     0.8862    |\n",
    "|     10    |         8          |     0.9866     |     0.9126    |\n",
    "|     15    |         8          |     0.9996     |     0.9004    |\n",
    "+-----------+--------------------+----------------+---------------+"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
